{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bb96b2d-913d-4043-8b81-e952c791cd3d",
   "metadata": {},
   "source": [
    "# Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63ba287b-262b-44b8-9146-6b1590ce4a56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro\\spark-3.5.0-bin-hadoop3\n",
      "C:\\Users\\pedro\\hadoop3.0\n",
      "C:\\Program Files\\Java\\jdk1.8.0_202\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Padrões do Sistema e Ambientes\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import logging\n",
    "import secrets\n",
    "from functools import reduce\n",
    "\n",
    "# Configuração de Ambientes Spark e Hadoop\n",
    "print(os.environ.get(\"SPARK_HOME\"))\n",
    "print(os.environ.get(\"HADOOP_HOME\"))\n",
    "print(os.environ.get(\"JAVA_HOME\"))\n",
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n",
    "\n",
    "# Pacotes de Análise e Manipulação de Dados\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "# Spark\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SQLContext, SparkConf, StorageLevel\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "from pyspark.sql.functions import (\n",
    "    regexp_replace, when, length, to_date, upper, lower, col, split, explode,\n",
    "    coalesce, concat_ws, concat, lit, broadcast, regexp_extract, month, year,\n",
    "    expr, udf, row_number, isnan, count, monotonically_increasing_id, var_samp\n",
    ")\n",
    "\n",
    "# Pyspark Machine Learning e Ferramentas Estatísticas\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import (\n",
    "    StringIndexer, VectorAssembler, ChiSqSelector, VarianceThresholdSelector, \n",
    "    UnivariateFeatureSelector, RFormula, VectorSlicer, OneHotEncoder, StandardScaler\n",
    ")\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.stat import ChiSquareTest\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor\n",
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "# XGBoost para Spark\n",
    "from xgboost.spark import SparkXGBClassifier\n",
    "\n",
    "# Geopy para Geocodificação\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "# Hyperopt para Otimização de Hiperparâmetros\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, space_eval, tpe\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "# MLflow para Gerenciamento de Modelos\n",
    "#import mlflow\n",
    "\n",
    "# Visualização de Dados\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import mpld3\n",
    "import missingno as msno\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyoff\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import chart_studio\n",
    "import chart_studio.plotly as py\n",
    "import chart_studio.tools as tls\n",
    "\n",
    "# Inicialização de Ferramentas\n",
    "import findspark\n",
    "findspark.init()\n",
    "pyoff.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a139bb3-0fbc-4795-8512-c3d02d0412e8",
   "metadata": {},
   "source": [
    "# Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a29bfd-98ef-48a5-a9d6-22aa065ef033",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder \n",
    "    .master(\"local[*]\") \n",
    "    .appName(\"Spark Optimization\")   \n",
    "    .config(\"spark.driver.cores\", \"3\")   # Alocando 3 núcleos para o driver\n",
    "    .config(\"spark.driver.memory\", \"12g\")  # 12 GB de RAM para o driver\n",
    "    .config(\"spark.executor.instances\", \"5\")   # Configurando para 5 executores\n",
    "    .config(\"spark.executor.cores\", \"2\")   # Cada executor terá 2 núcleos\n",
    "    .config(\"spark.executor.memory\", \"6g\")   # Cada executor terá 6 GB de RAM\n",
    "    .config(\"spark.executor.memoryOverhead\", \"2g\")   # Overhead adicional para evitar spill para disco\n",
    "    .config(\"spark.memory.fraction\", \"0.6\")  \n",
    "    .config(\"spark.memory.storageFraction\", \"0.5\")   \n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\")   \n",
    "    .config(\"spark.memory.offHeap.size\", \"4g\")   # Memória off-heap adicional para operações fora do heap JVM\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\")   \n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", \"400m\")  # Broadcast join otimizado para joins pequenos\n",
    "    .config(\"spark.default.parallelism\", \"32\")   # Paralelismo adequado ao tamanho do dataset\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"32\")   # Número de partições para operações de shuffle\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)   \n",
    "    .config(\"spark.sql.adaptive.enabled\", True) \n",
    "    .config(\"spark.sql.cbo.enabled\", True) \n",
    "    .config(\"spark.sql.repl.eagerEval.maxNumRows\", 10)  \n",
    "    .config(\"spark.shuffle.compress\", \"true\")   \n",
    "    .config(\"spark.storage.level\", \"MEMORY_AND_DISK\")   \n",
    "    .config(\"spark.rdd.compress\", \"true\")   \n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.JavaSerializer\")\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c98a83-7eda-417e-b5e5-7ca44adce474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bcc0a53-133b-4e2b-a6f2-34c3af9f9669",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark Optimization</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1feb4dda750>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05f82d27-7727-4b44-be80-870c5dfc8dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_logistic_reg(df, categorical_cols, numeric_features, response_col):\n",
    "    # Indexação das colunas categóricas\n",
    "    indexers = [\n",
    "        StringIndexer(inputCol=col, outputCol=col + \"_index\", handleInvalid=\"skip\")\n",
    "        for col in categorical_cols\n",
    "    ]\n",
    "\n",
    "    # Indexação da coluna de resposta\n",
    "    indexers.append(StringIndexer(inputCol=response_col, outputCol=response_col + \"_index\", handleInvalid=\"skip\"))\n",
    "\n",
    "    # Assembler para criar o vetor de features\n",
    "    input_cols = [col + \"_index\" for col in categorical_cols] + numeric_features\n",
    "    assembler = VectorAssembler(inputCols=input_cols, outputCol=\"features\")\n",
    "\n",
    "    # Pipeline para processar indexação e assembler\n",
    "    pipeline = Pipeline(stages=indexers + [assembler])\n",
    "    df_transformed = pipeline.fit(df).transform(df)\n",
    "\n",
    "    # Configurando a Regressão Logística com ElasticNet\n",
    "    lr = LogisticRegression(featuresCol=\"features\", labelCol=response_col + \"_index\", elasticNetParam=0.5)\n",
    "    lr_model = lr.fit(df_transformed)\n",
    "\n",
    "    # Obtendo os coeficientes das features\n",
    "    coefficients = lr_model.coefficients.toArray()\n",
    "\n",
    "    # Vinculando coeficientes com os nomes das colunas\n",
    "    important_features = sorted(zip(input_cols, coefficients), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "    # Definindo um threshold para selecionar as colunas mais importantes\n",
    "    threshold = 0.05  # Ajuste conforme necessário\n",
    "    significant_columns = [name for name, coef in important_features if abs(coef) > threshold]\n",
    "\n",
    "    print(\"Colunas significativas com base na Regressão Logística ElasticNet:\")\n",
    "    print(significant_columns)\n",
    "    \n",
    "    return significant_columns\n",
    "\n",
    "# Chamando a função para regressão logística\n",
    "\n",
    "\n",
    "def feature_importance_linear_reg(df, categorical_cols, numeric_features, response_col):\n",
    "    # Indexação das colunas categóricas\n",
    "    indexers = [\n",
    "        StringIndexer(inputCol=col, outputCol=col + \"_index\", handleInvalid=\"skip\")\n",
    "        for col in categorical_cols\n",
    "    ]\n",
    "\n",
    "    # Assembler para criar o vetor de features\n",
    "    input_cols = [col + \"_index\" for col in categorical_cols] + numeric_features\n",
    "    assembler = VectorAssembler(inputCols=input_cols, outputCol=\"features\")\n",
    "\n",
    "    # Pipeline para processar indexação e assembler\n",
    "    pipeline = Pipeline(stages=indexers + [assembler])\n",
    "    df_transformed = pipeline.fit(df).transform(df)\n",
    "\n",
    "    # Configurando a Regressão Linear com ElasticNet (regularização combinando L1 e L2)\n",
    "    lr = LinearRegression(featuresCol=\"features\", labelCol=response_col, elasticNetParam=0.5)\n",
    "    lr_model = lr.fit(df_transformed)\n",
    "\n",
    "    # Obtendo os coeficientes das features\n",
    "    coefficients = lr_model.coefficients.toArray()\n",
    "\n",
    "    # Vinculando coeficientes com os nomes das colunas\n",
    "    important_features = sorted(zip(input_cols, coefficients), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "    # Definindo um threshold para selecionar as colunas mais importantes\n",
    "    threshold = 0.05  # Ajuste conforme necessário\n",
    "    significant_columns = [name for name, coef in important_features if abs(coef) > threshold]\n",
    "\n",
    "    print(\"Colunas significativas com base na Regressão Linear ElasticNet:\")\n",
    "    print(significant_columns)\n",
    "    \n",
    "    return significant_columns\n",
    "\n",
    "def feature_importance_rf_reg(df, categorical_cols, numeric_features, response_col):\n",
    "    # Remover a variável dependente das listas de variáveis preditoras\n",
    "    if response_col in categorical_cols:\n",
    "        categorical_cols.remove(response_col)\n",
    "    if response_col in numeric_features:\n",
    "        numeric_features.remove(response_col)\n",
    "\n",
    "    # Indexação das colunas categóricas\n",
    "    indexers = [\n",
    "        StringIndexer(inputCol=col, outputCol=col + \"_index\", handleInvalid=\"skip\")\n",
    "        for col in categorical_cols\n",
    "    ]\n",
    "\n",
    "    # Assembler para criar o vetor de features\n",
    "    input_cols = [col + \"_index\" for col in categorical_cols] + numeric_features\n",
    "    assembler = VectorAssembler(inputCols=input_cols, outputCol=\"features\")\n",
    "\n",
    "    # Pipeline para processar indexação e assembler\n",
    "    pipeline = Pipeline(stages=indexers + [assembler])\n",
    "    df_transformed = pipeline.fit(df).transform(df)\n",
    "\n",
    "    # Treinando um RandomForestRegressor para avaliar a importância das features com maxBins ajustado\n",
    "    rf = RandomForestRegressor(featuresCol=\"features\", labelCol=response_col, maxBins=5500)\n",
    "    rf_model = rf.fit(df_transformed)\n",
    "\n",
    "    # Obtendo as importâncias das features\n",
    "    importances = rf_model.featureImportances\n",
    "\n",
    "    # Vinculando importâncias com os nomes das colunas\n",
    "    important_features = sorted(zip(input_cols, importances), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "    # Definindo um threshold para selecionar as colunas mais importantes\n",
    "    threshold = 0.05  # Ajuste conforme necessário\n",
    "    significant_columns = [name for name, importance in important_features if importance > threshold]\n",
    "\n",
    "    print(\"Colunas significativas com base na importância do RandomForestRegressor:\")\n",
    "    print(significant_columns)\n",
    "    \n",
    "    return significant_columns\n",
    "\n",
    "def feature_importance_rf_class(df, categorical_cols, numeric_features, response_col):\n",
    "    # Limpeza e preparação das colunas\n",
    "    df = clean_up_columns(df, response_col)\n",
    "    \n",
    "    # Definir as colunas categóricas e numéricas se necessário\n",
    "    categorical_cols = [t[0] for t in df.dtypes if t[1] == 'string']\n",
    "    numeric_features = [t[0] for t in df.dtypes if t[1] in ('int', 'double', 'float', 'long')]\n",
    "\n",
    "    # Garantir que a variável resposta não esteja nas listas\n",
    "    if response_col in categorical_cols:\n",
    "        categorical_cols.remove(response_col)\n",
    "    if response_col in numeric_features:\n",
    "        numeric_features.remove(response_col)\n",
    "\n",
    "    # Indexação das colunas categóricas\n",
    "    indexers = [\n",
    "        StringIndexer(inputCol=col, outputCol=col + \"_index\", handleInvalid=\"skip\")\n",
    "        for col in categorical_cols\n",
    "    ]\n",
    "\n",
    "    # Indexação da coluna de resposta\n",
    "    indexers.append(StringIndexer(inputCol=response_col, outputCol=response_col + \"_index\", handleInvalid=\"skip\"))\n",
    "\n",
    "    # Assembler para criar o vetor de features\n",
    "    input_cols = [col + \"_index\" for col in categorical_cols] + numeric_features\n",
    "    assembler = VectorAssembler(inputCols=input_cols, outputCol=\"features\")\n",
    "\n",
    "    # Pipeline para processar indexação e assembler\n",
    "    pipeline = Pipeline(stages=indexers + [assembler])\n",
    "    df_transformed = pipeline.fit(df).transform(df)\n",
    "\n",
    "    # Treinando um RandomForest para avaliar a importância das features\n",
    "    rf = RandomForestClassifier(featuresCol=\"features\", labelCol=response_col + \"_index\")\n",
    "    rf_model = rf.fit(df_transformed)\n",
    "\n",
    "    # Obtendo as importâncias das features\n",
    "    importances = rf_model.featureImportances\n",
    "\n",
    "    # Vinculando importâncias com os nomes das colunas\n",
    "    important_features = sorted(zip(input_cols, importances), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Definindo um threshold para selecionar as colunas mais importantes\n",
    "    threshold = 0.05  # Ajuste conforme necessário\n",
    "    significant_columns = [name for name, importance in important_features if importance > threshold]\n",
    "\n",
    "    print(\"Colunas significativas com base na importância do RandomForest:\")\n",
    "    print(significant_columns)\n",
    "    \n",
    "    return significant_columns\n",
    "\n",
    "def univariate_feature_selector(df, categorical_cols, numeric_features, response_col, selectionThreshold=5):\n",
    "    # Limpeza e preparação das colunas\n",
    "    df = clean_up_columns(df, response_col)\n",
    "\n",
    "    # Indexação de colunas categóricas\n",
    "    indexers = [StringIndexer(inputCol=c, outputCol=c + \"_index\", handleInvalid=\"skip\") for c in categorical_cols]\n",
    "\n",
    "    # Indexação da coluna de resposta\n",
    "    indexer_response = StringIndexer(inputCol=response_col, outputCol=\"label\", handleInvalid=\"skip\")\n",
    "\n",
    "    # Assembler para combinar colunas numéricas e categóricas indexadas em um vetor de features\n",
    "    input_cols = [c + \"_index\" for c in categorical_cols] + numeric_features\n",
    "    assembler = VectorAssembler(inputCols=input_cols, outputCol=\"features\")\n",
    "\n",
    "    # Configuração do UnivariateFeatureSelector\n",
    "    selector = UnivariateFeatureSelector(\n",
    "        featuresCol=\"features\",\n",
    "        outputCol=\"selectedFeatures\",\n",
    "        labelCol=\"label\",\n",
    "        selectionMode=\"numTopFeatures\"\n",
    "    ).setFeatureType(\"continuous\").setLabelType(\"categorical\").setSelectionThreshold(selectionThreshold)\n",
    "\n",
    "    # Pipeline para realizar a transformação\n",
    "    pipeline = Pipeline(stages=indexers + [indexer_response, assembler, selector])\n",
    "    model = pipeline.fit(df)\n",
    "    df_transformed = model.transform(df)\n",
    "\n",
    "    # Obter os índices das features selecionadas\n",
    "    selected_indices = model.stages[-1].selectedFeatures  # Último estágio é o UnivariateFeatureSelector\n",
    "\n",
    "    # Mapear os índices selecionados de volta para os nomes das colunas\n",
    "    selected_feature_names = [input_cols[index] for index in selected_indices]\n",
    "\n",
    "    # Imprimir os nomes das colunas das features selecionadas\n",
    "    print(\"Colunas selecionadas:\", selected_feature_names)\n",
    "\n",
    "    return selected_feature_names\n",
    "\n",
    "def missing_values_table_spark(df):\n",
    "    \"\"\"\n",
    "    Cria uma tabela resumindo a quantidade e a porcentagem de valores ausentes em cada coluna do DataFrame PySpark.\n",
    "\n",
    "    Args:\n",
    "    df (spark.DataFrame): DataFrame para análise de valores ausentes.\n",
    "\n",
    "    Returns:\n",
    "    spark.DataFrame: Uma tabela com o número e a porcentagem de valores ausentes por coluna.\n",
    "    \"\"\"\n",
    "    # Calcula o número total de linhas no DataFrame\n",
    "    total_rows = df.count()\n",
    "\n",
    "    # Calcula o número total de valores ausentes por coluna\n",
    "    missing_count = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "\n",
    "    # Calcula a porcentagem de valores ausentes por coluna\n",
    "    missing_percent = df.select([(count(when(col(c).isNull(), c)) / total_rows * 100).alias(c) for c in df.columns])\n",
    "\n",
    "    # Preparando para juntar contagens e percentagens\n",
    "    missing_count = missing_count.withColumnRenamed(missing_count.columns[0], 'Missing Values')\n",
    "    missing_percent = missing_percent.withColumnRenamed(missing_percent.columns[0], '% of Total Values')\n",
    "\n",
    "    # Junta as contagens e as percentagens em um DataFrame\n",
    "    missing_table = missing_count.join(missing_percent)\n",
    "\n",
    "    # Ordena as colunas com valores ausentes por porcentagem de forma decrescente\n",
    "    missing_table = missing_table.orderBy(col('% of Total Values').desc())\n",
    "\n",
    "    # Imprime um resumo das colunas com valores ausentes\n",
    "    print(\"Your selected dataframe has \" + str(len(df.columns)) + \" columns.\\n\"      \n",
    "          \"There are \" + str(missing_table.count()) + \" columns that have missing values.\")\n",
    "\n",
    "    return missing_table\n",
    "\n",
    "\n",
    "\n",
    "def r_formula_with_feature_importance(df, categorical_cols, numeric_features, response_col):\n",
    "    # Definindo a fórmula\n",
    "    predictor_cols = categorical_cols + numeric_features\n",
    "    formula_expression = f\"{response_col} ~ \" + \" + \".join(predictor_cols)\n",
    "\n",
    "    # Configuração do RFormula\n",
    "    formula = RFormula(\n",
    "        formula=formula_expression,\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"label\"\n",
    "    )\n",
    "\n",
    "    # Pipeline para aplicar a RFormula\n",
    "    pipeline = Pipeline(stages=[formula])\n",
    "    df_transformed = pipeline.fit(df).transform(df)\n",
    "\n",
    "    # Dividindo os dados em treino e teste (opcional)\n",
    "    train_df, test_df = df_transformed.randomSplit([0.75, 0.25], seed=1234)\n",
    "\n",
    "    # Usando RandomForest para avaliar a importância das features\n",
    "    rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"label\")\n",
    "    rf_model = rf.fit(train_df)\n",
    "\n",
    "    # Obtendo as importâncias das features\n",
    "    importances = rf_model.featureImportances\n",
    "\n",
    "    # Vinculando importâncias com os nomes das colunas preditivas\n",
    "    feature_list = categorical_cols + numeric_features\n",
    "    important_features = sorted(zip(feature_list, importances), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Exibindo as colunas mais significativas\n",
    "    print(\"Colunas significativas com base na importância do RandomForest:\")\n",
    "    for feature, importance in important_features:\n",
    "        print(f\"Feature: {feature}, Importance: {importance}\")\n",
    "\n",
    "    # Avaliar o modelo no conjunto de teste (opcional)\n",
    "    predictions = rf_model.transform(test_df)\n",
    "    evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(f\"Root Mean Squared Error (RMSE) no conjunto de teste: {rmse}\")\n",
    "    \n",
    "    return important_features\n",
    "\n",
    "def vector_slicer_function(df, categorical_cols, numeric_features, response_col):\n",
    "    # Limpeza e preparação das colunas\n",
    "    df = clean_up_columns(df, response_col)\n",
    "\n",
    "    # Indexação das colunas categóricas\n",
    "    indexers = [StringIndexer(inputCol=col, outputCol=col + \"_index\", handleInvalid=\"skip\") for col in categorical_cols]\n",
    "\n",
    "    # Assembler para combinar as colunas indexadas e numéricas em um vetor de features\n",
    "    input_cols = [col + \"_index\" for col in categorical_cols] + numeric_features\n",
    "    assembler = VectorAssembler(inputCols=input_cols, outputCol=\"features\")\n",
    "\n",
    "    # Pipeline para processar a indexação e assembler\n",
    "    pipeline = Pipeline(stages=indexers + [assembler])\n",
    "    df_transformed = pipeline.fit(df).transform(df)\n",
    "\n",
    "    # Slicing das features\n",
    "    indices_to_slice = [0, 1, 3, 4, 5]  # Ajuste conforme necessário\n",
    "    vs = VectorSlicer(inputCol=\"features\", outputCol=\"selectedFeatures\", indices=indices_to_slice)\n",
    "    df_sliced = vs.transform(df_transformed)\n",
    "\n",
    "    # Mapeando os índices para os nomes das colunas\n",
    "    selected_feature_names = [input_cols[index] for index in indices_to_slice]\n",
    "\n",
    "    # Exibindo as features selecionadas e seus nomes\n",
    "    df_sliced.select(\"selectedFeatures\").show(truncate=False)\n",
    "    print(\"Nomes das colunas selecionadas:\", selected_feature_names)\n",
    "\n",
    "    return selected_feature_names\n",
    "\n",
    "\n",
    "def variance_threshold_selector(df, numeric_features, varianceThreshold=0.5):\n",
    "    # Assembler para criar o vetor de features numéricas\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=numeric_features,\n",
    "        outputCol=\"features\")\n",
    "\n",
    "    # Aplicar o assembler ao DataFrame\n",
    "    df_assembled = assembler.transform(df)\n",
    "\n",
    "    # Configurando o VarianceThresholdSelector\n",
    "    selector = VarianceThresholdSelector(\n",
    "        featuresCol=\"features\",\n",
    "        outputCol=\"selectedFeatures\",\n",
    "        varianceThreshold=varianceThreshold  # Definir um limiar de variância apropriado\n",
    "    )\n",
    "\n",
    "    # Aplicando o selector ao DataFrame\n",
    "    model = selector.fit(df_assembled)\n",
    "    df_selected = model.transform(df_assembled)\n",
    "\n",
    "    # Obter os índices das features selecionadas\n",
    "    selected_indices = model.selectedFeatures\n",
    "\n",
    "    # Criar uma lista de nomes de colunas mapeando de volta usando os índices selecionados\n",
    "    selected_feature_names = [numeric_features[index] for index in selected_indices]\n",
    "\n",
    "    print(\"Colunas selecionadas com variância acima do limiar:\", selected_feature_names)\n",
    "\n",
    "    return selected_feature_names\n",
    "\n",
    "def chi_sq_selector(df, categorical_cols, response_col, numTopFeatures=4):\n",
    "    # Indexação de colunas categóricas\n",
    "    indexers = [StringIndexer(inputCol=c, outputCol=c + \"_index\") for c in categorical_cols] + \\\n",
    "               [StringIndexer(inputCol=response_col, outputCol=\"label\")]\n",
    "\n",
    "    # Assembler para combinar as colunas categóricas indexadas em um vetor de features\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=[c + \"_index\" for c in categorical_cols],\n",
    "        outputCol=\"features\")\n",
    "\n",
    "    # Configuração do ChiSqSelector\n",
    "    selector = ChiSqSelector(numTopFeatures=numTopFeatures, featuresCol=\"features\",\n",
    "                             outputCol=\"selectedFeatures\", labelCol=\"label\")\n",
    "\n",
    "    # Pipeline para processar tudo\n",
    "    pipeline = Pipeline(stages=indexers + [assembler, selector])\n",
    "    model = pipeline.fit(df)\n",
    "    df_transformed = model.transform(df)\n",
    "\n",
    "    # Obter o modelo do selector para acessar os índices das features selecionadas\n",
    "    selected_features_model = model.stages[-1]\n",
    "    selected_indices = selected_features_model.selectedFeatures\n",
    "\n",
    "    # Criar uma lista de nomes de colunas mapeando de volta usando os índices selecionados\n",
    "    selected_feature_names = [categorical_cols[index] for index in selected_indices]\n",
    "\n",
    "    print(\"Colunas selecionadas pelo teste Chi-quadrado:\")\n",
    "    print(selected_feature_names)\n",
    "\n",
    "    return selected_feature_names\n",
    "\n",
    "def clean_up_columns(df, response_col):\n",
    "    if \"label\" in df.columns:\n",
    "        df = df.drop(\"label\")\n",
    "    if f\"{response_col}_index\" in df.columns:\n",
    "        df = df.drop(f\"{response_col}_index\")\n",
    "    if f\"old_{response_col}_index\" in df.columns:\n",
    "        df = df.drop(f\"old_{response_col}_index\")\n",
    "    return df\n",
    "\n",
    "def univariate_feature_selector_var_num(df, categorical_cols, numeric_features, response_col, selectionThreshold=5):\n",
    "    # Limpeza de colunas, se necessário\n",
    "    df = clean_up_columns(df, response_col)\n",
    "\n",
    "    # Garantir que a variável dependente não esteja nas listas de variáveis preditivas\n",
    "    if response_col in categorical_cols:\n",
    "        categorical_cols.remove(response_col)\n",
    "    if response_col in numeric_features:\n",
    "        numeric_features.remove(response_col)\n",
    "\n",
    "    # Indexação de colunas categóricas\n",
    "    indexers = [StringIndexer(inputCol=c, outputCol=c + \"_index\", handleInvalid=\"keep\") for c in categorical_cols]\n",
    "\n",
    "    # Assembler para combinar as colunas categóricas indexadas e as numéricas em um vetor de features\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=[c + \"_index\" for c in categorical_cols] + numeric_features,\n",
    "        outputCol=\"features\"\n",
    "    )\n",
    "\n",
    "    # Definir o tipo de seleção baseado no tipo da variável dependente\n",
    "    # Se a variável resposta for categórica, use \"categorical\", caso contrário \"continuous\"\n",
    "    if df.schema[response_col].dataType.simpleString() in ['int', 'double', 'float', 'long']:\n",
    "        label_type = \"continuous\"\n",
    "    else:\n",
    "        label_type = \"categorical\"\n",
    "\n",
    "    # Configurar o UnivariateFeatureSelector\n",
    "    selector = UnivariateFeatureSelector(\n",
    "        featuresCol=\"features\",\n",
    "        outputCol=\"selectedFeatures\",\n",
    "        labelCol=response_col,  # Usar a coluna de resposta diretamente\n",
    "        selectionMode=\"numTopFeatures\"\n",
    "    )\n",
    "\n",
    "    selector.setFeatureType(\"continuous\").setLabelType(label_type).setSelectionThreshold(selectionThreshold)\n",
    "\n",
    "    # Pipeline para transformar os dados\n",
    "    pipeline = Pipeline(stages=indexers + [assembler, selector])\n",
    "    model = pipeline.fit(df)\n",
    "    df_transformed = model.transform(df)\n",
    "\n",
    "    # Obter os índices das features selecionadas\n",
    "    selected_indices = model.stages[-1].selectedFeatures  # O último estágio é o UnivariateFeatureSelector\n",
    "\n",
    "    # Lista de todas as colunas que foram usadas para criar o vetor de features\n",
    "    all_features = [col + \"_index\" for col in categorical_cols] + numeric_features\n",
    "\n",
    "    # Mapear os índices selecionados de volta para os nomes das colunas\n",
    "    selected_feature_names = [all_features[index] for index in selected_indices]\n",
    "\n",
    "    # Imprimir os nomes das colunas das features selecionadas\n",
    "    print(\"Colunas selecionadas:\", selected_feature_names)\n",
    "\n",
    "    return selected_feature_names\n",
    "\n",
    "\n",
    "def feature_importance_linear_reg(df, categorical_cols, numeric_features, response_col):\n",
    "    # Remover a variável dependente das listas de variáveis preditoras\n",
    "    if response_col in categorical_cols:\n",
    "        categorical_cols.remove(response_col)\n",
    "    if response_col in numeric_features:\n",
    "        numeric_features.remove(response_col)\n",
    "\n",
    "    # Indexação das colunas categóricas\n",
    "    indexers = [\n",
    "        StringIndexer(inputCol=col, outputCol=col + \"_index\", handleInvalid=\"skip\")\n",
    "        for col in categorical_cols\n",
    "    ]\n",
    "\n",
    "    # Assembler para criar o vetor de features\n",
    "    input_cols = [col + \"_index\" for col in categorical_cols] + numeric_features\n",
    "    assembler = VectorAssembler(inputCols=input_cols, outputCol=\"features\")\n",
    "\n",
    "    # Pipeline para processar indexação e assembler\n",
    "    pipeline = Pipeline(stages=indexers + [assembler])\n",
    "    df_transformed = pipeline.fit(df).transform(df)\n",
    "\n",
    "    # Configurando a Regressão Linear com ElasticNet (regularização combinando L1 e L2)\n",
    "    lr = LinearRegression(featuresCol=\"features\", labelCol=response_col, elasticNetParam=0.5)\n",
    "    lr_model = lr.fit(df_transformed)\n",
    "\n",
    "    # Obtendo os coeficientes das features\n",
    "    coefficients = lr_model.coefficients.toArray()\n",
    "\n",
    "    # Vinculando coeficientes com os nomes das colunas\n",
    "    important_features = sorted(zip(input_cols, coefficients), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "    # Definindo um threshold para selecionar as colunas mais importantes\n",
    "    threshold = 0.05  # Ajuste conforme necessário\n",
    "    significant_columns = [name for name, coef in important_features if abs(coef) > threshold]\n",
    "\n",
    "    print(\"Colunas significativas com base na Regressão Linear ElasticNet:\")\n",
    "    print(significant_columns)\n",
    "    \n",
    "    return significant_columns\n",
    "\n",
    "def pearson_correlation(df, numeric_features):\n",
    "    corr_matrix = []\n",
    "    for x in numeric_features:\n",
    "        temp = []\n",
    "        for y in numeric_features:\n",
    "            temp.append(df.stat.corr(x, y, method='pearson'))\n",
    "        corr_matrix.append(temp)\n",
    "    corr_df = pd.DataFrame(corr_matrix, index=numeric_features, columns=numeric_features)\n",
    "    \n",
    "    ## corr_df.to_csv(\"pearson_correlation.csv\", index=False)\n",
    "    return corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d6d0b-8517-43f1-97c5-ede442c8ef50",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a47e096-5313-4cea-aedc-17ceb30a4c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('C:/Users/pedro/Documents/Curso de pos graduação de EST/DADOS_CNPJ/df_final_filtrado_s_missing/').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0621d6be-2b7a-4712-9008-43f2f1074f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.NM_MATRIZ_FILIAL,df.NAT_JURICA , df.NM_QUALIFICACAO,df.CEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63f4dd3-bf26-4018-ba27-561f34c6a4a0",
   "metadata": {},
   "source": [
    "## Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62720cb5-fab3-4d8f-978f-ab401b947aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificar as colunas que você deseja transformar\n",
    "columns_to_cast = [\n",
    "    \"LON\",\n",
    "    \"LAT\"\n",
    "]\n",
    "\n",
    "# Substituir ',' por '.' nas colunas selecionadas\n",
    "for column in columns_to_cast:\n",
    "    df = df.withColumn(column, F.regexp_replace(F.col(column), ',', '.'))\n",
    "\n",
    "# Aplicar a transformação de tipo para FLOAT\n",
    "for column in columns_to_cast:\n",
    "    df = df.withColumn(column, F.col(column).cast(\"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fbebb38-ac28-46dd-afea-767b6cffdd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 24 columns.\n",
      "There are 1 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Missing Values</th><th>NOME_EMPRESA</th><th>NOME_FANTASIA</th><th>CAP_SOCIAL</th><th>SEXO_PROB</th><th>CNAE</th><th>ano_cadastro</th><th>mes_cadastro</th><th>TIPO_LOUGRADOURO</th><th>CEP</th><th>MUNICIPIO</th><th>UF</th><th>PROVEDOR</th><th>LON</th><th>LAT</th><th>DDD1</th><th>TIPO_TELEFONE_FINAL</th><th>OPERADORA</th><th>renda_per_capita</th><th>PRODUTO_INTERNO_BRUTO_A_PREOS_CORRENTES_R_1000</th><th>PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORRENTES_R_100</th><th>ATIVIDADE_COM_MAIOR_VALOR_ADICIONADO_BRUTO</th><th>ATIVIDADE_COM_SEGUNDO_MAIOR_VALOR_ADICIONADO_BRUTO</th><th>IDHM_2010</th><th>% of Total Values</th><th>NOME_EMPRESA</th><th>NOME_FANTASIA</th><th>CAP_SOCIAL</th><th>SEXO_PROB</th><th>CNAE</th><th>ano_cadastro</th><th>mes_cadastro</th><th>TIPO_LOUGRADOURO</th><th>CEP</th><th>MUNICIPIO</th><th>UF</th><th>PROVEDOR</th><th>LON</th><th>LAT</th><th>DDD1</th><th>TIPO_TELEFONE_FINAL</th><th>OPERADORA</th><th>renda_per_capita</th><th>PRODUTO_INTERNO_BRUTO_A_PREOS_CORRENTES_R_1000</th><th>PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORRENTES_R_100</th><th>ATIVIDADE_COM_MAIOR_VALOR_ADICIONADO_BRUTO</th><th>ATIVIDADE_COM_SEGUNDO_MAIOR_VALOR_ADICIONADO_BRUTO</th><th>IDHM_2010</th></tr>\n",
       "<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------+------------+-------------+----------+---------+----+------------+------------+----------------+---+---------+---+--------+---+---+----+-------------------+---------+----------------+----------------------------------------------+--------------------------------------------------------+------------------------------------------+--------------------------------------------------+---------+-----------------+------------+-------------+----------+---------+----+------------+------------+----------------+---+---------+---+--------+---+---+----+-------------------+---------+----------------+----------------------------------------------+--------------------------------------------------------+------------------------------------------+--------------------------------------------------+---------+\n",
       "|Missing Values|NOME_EMPRESA|NOME_FANTASIA|CAP_SOCIAL|SEXO_PROB|CNAE|ano_cadastro|mes_cadastro|TIPO_LOUGRADOURO|CEP|MUNICIPIO| UF|PROVEDOR|LON|LAT|DDD1|TIPO_TELEFONE_FINAL|OPERADORA|renda_per_capita|PRODUTO_INTERNO_BRUTO_A_PREOS_CORRENTES_R_1000|PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORRENTES_R_100|ATIVIDADE_COM_MAIOR_VALOR_ADICIONADO_BRUTO|ATIVIDADE_COM_SEGUNDO_MAIOR_VALOR_ADICIONADO_BRUTO|IDHM_2010|% of Total Values|NOME_EMPRESA|NOME_FANTASIA|CAP_SOCIAL|SEXO_PROB|CNAE|ano_cadastro|mes_cadastro|TIPO_LOUGRADOURO|CEP|MUNICIPIO| UF|PROVEDOR|LON|LAT|DDD1|TIPO_TELEFONE_FINAL|OPERADORA|renda_per_capita|PRODUTO_INTERNO_BRUTO_A_PREOS_CORRENTES_R_1000|PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORRENTES_R_100|ATIVIDADE_COM_MAIOR_VALOR_ADICIONADO_BRUTO|ATIVIDADE_COM_SEGUNDO_MAIOR_VALOR_ADICIONADO_BRUTO|IDHM_2010|\n",
       "+--------------+------------+-------------+----------+---------+----+------------+------------+----------------+---+---------+---+--------+---+---+----+-------------------+---------+----------------+----------------------------------------------+--------------------------------------------------------+------------------------------------------+--------------------------------------------------+---------+-----------------+------------+-------------+----------+---------+----+------------+------------+----------------+---+---------+---+--------+---+---+----+-------------------+---------+----------------+----------------------------------------------+--------------------------------------------------------+------------------------------------------+--------------------------------------------------+---------+\n",
       "|             0|           0|            0|         0|        0|   0|           0|           0|               0|  0|        0|  0|       0|  0|  0|   0|                  0|        0|               0|                                             0|                                                       0|                                         0|                                                 0|        0|              0.0|         0.0|          0.0|       0.0|      0.0| 0.0|         0.0|         0.0|             0.0|0.0|      0.0|0.0|     0.0|0.0|0.0| 0.0|                0.0|      0.0|             0.0|                                           0.0|                                                     0.0|                                       0.0|                                               0.0|      0.0|\n",
       "+--------------+------------+-------------+----------+---------+----+------------+------------+----------------+---+---------+---+--------+---+---+----+-------------------+---------+----------------+----------------------------------------------+--------------------------------------------------------+------------------------------------------+--------------------------------------------------+---------+-----------------+------------+-------------+----------+---------+----+------------+------------+----------------+---+---------+---+--------+---+---+----+-------------------+---------+----------------+----------------------------------------------+--------------------------------------------------------+------------------------------------------+--------------------------------------------------+---------+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_table_spark(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc56ac6-2e3f-4e74-8133-5195e7b6f06e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15cc765b-444b-4035-90f2-a325d3980fa8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def clean_up_columns(df, response_col):\n",
    "    if \"label\" in df.columns:\n",
    "        df = df.drop(\"label\")\n",
    "    if f\"{response_col}_index\" in df.columns:\n",
    "        df = df.drop(f\"{response_col}_index\")\n",
    "    if f\"old_{response_col}_index\" in df.columns:\n",
    "        df = df.drop(f\"old_{response_col}_index\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def univariate_feature_selector(df, categorical_cols, numeric_features, response_col, selectionThreshold=5):\n",
    "    df = clean_up_columns(df, response_col)\n",
    "    \n",
    "    # Lista de colunas numéricas\n",
    "    numeric_features = numeric_features\n",
    "\n",
    "    # Identificar as colunas categóricas\n",
    "    categorical_cols = categorical_cols\n",
    "\n",
    "    # Supondo que uma das colunas numéricas seja a resposta e precisamos transformá-la\n",
    "    response_col = 'STATUS'  # Variável a ser predita\n",
    "\n",
    "    # Indexação de colunas categóricas e coluna de resposta\n",
    "    indexers = [StringIndexer(inputCol=c, outputCol=c+\"_index\", handleInvalid=\"keep\") for c in categorical_cols]\n",
    "    indexer_response = StringIndexer(inputCol=\"STATUS\", outputCol=\"label\", handleInvalid=\"keep\")\n",
    "\n",
    "    # Assembler para combinar colunas numéricas e categóricas indexadas em um vetor de features\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=[c+\"_index\" for c in categorical_cols] + numeric_features,\n",
    "        outputCol=\"features\")\n",
    "\n",
    "    selector = UnivariateFeatureSelector(\n",
    "        featuresCol=\"features\",\n",
    "        outputCol=\"selectedFeatures\",\n",
    "        labelCol=\"label\",  # Usar \"label\", pois é o nome configurado pelo indexer_response\n",
    "        selectionMode=\"numTopFeatures\"  # ou use outro modo conforme necessário\n",
    "    )\n",
    "\n",
    "    selector.setFeatureType(\"continuous\").setLabelType(\"categorical\").setSelectionThreshold(selectionThreshold)  # ajuste conforme necessário\n",
    "\n",
    "    # Adicionando a transformação da label ao pipeline\n",
    "    pipeline = Pipeline(stages=indexers + [indexer_response, assembler, selector])\n",
    "    model = pipeline.fit(df)\n",
    "    df_transformed = model.transform(df)\n",
    "\n",
    "    # Obter os índices das features selecionadas\n",
    "    selected_indices = model.stages[-1].selectedFeatures  # O último estágio é o UnivariateFeatureSelector\n",
    "\n",
    "    # Lista de todas as colunas que foram usadas para criar o vetor de features\n",
    "    all_features = [col + \"_index\" for col in categorical_cols] + numeric_features\n",
    "\n",
    "    # Mapear os índices selecionados de volta para os nomes das colunas\n",
    "    selected_feature_names = [all_features[index] for index in selected_indices]\n",
    "\n",
    "    # Imprimir os nomes das colunas das features selecionadas\n",
    "    print(\"Colunas selecionadas:\", selected_feature_names)\n",
    "\n",
    "    return selected_feature_names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbc4d2e-8f1c-4008-bbd1-44b15fdbe6c5",
   "metadata": {},
   "source": [
    "# Criação de um index único"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15cccd4c-e6cc-4b41-836a-d920d0a25374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"index\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9c2bfb-a594-4c85-ae36-ff4d859b18ae",
   "metadata": {},
   "source": [
    "# Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "109d7aff-d861-436c-b1a9-134f15da6d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CNPJ: string (nullable = true)\n",
      " |-- NOME_EMPRESA: string (nullable = true)\n",
      " |-- NOME_FANTASIA: string (nullable = true)\n",
      " |-- CAP_SOCIAL: float (nullable = true)\n",
      " |-- SEXO_PROB: string (nullable = true)\n",
      " |-- CNAE: string (nullable = true)\n",
      " |-- ano_cadastro: integer (nullable = true)\n",
      " |-- mes_cadastro: integer (nullable = true)\n",
      " |-- TIPO_LOUGRADOURO: string (nullable = true)\n",
      " |-- CEP: integer (nullable = true)\n",
      " |-- MUNICIPIO: string (nullable = true)\n",
      " |-- UF: string (nullable = true)\n",
      " |-- PROVEDOR: string (nullable = true)\n",
      " |-- LON: float (nullable = true)\n",
      " |-- LAT: float (nullable = true)\n",
      " |-- DDD1: string (nullable = true)\n",
      " |-- TIPO_TELEFONE_FINAL: string (nullable = true)\n",
      " |-- OPERADORA: string (nullable = true)\n",
      " |-- renda_per_capita: float (nullable = true)\n",
      " |-- PRODUTO_INTERNO_BRUTO_A_PREOS_CORRENTES_R_1000: float (nullable = true)\n",
      " |-- PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORRENTES_R_100: float (nullable = true)\n",
      " |-- ATIVIDADE_COM_MAIOR_VALOR_ADICIONADO_BRUTO: string (nullable = true)\n",
      " |-- ATIVIDADE_COM_SEGUNDO_MAIOR_VALOR_ADICIONADO_BRUTO: string (nullable = true)\n",
      " |-- IDHM_2010: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0427d8-1fe9-4224-9336-eaa54e2fa70b",
   "metadata": {},
   "source": [
    "## Correlação de Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adae3a3b-2783-4bd9-8604-ff16cc2e602c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_features = [t[0] for t in df.dtypes if t[1] in ('int', 'double', 'float', 'long')]\n",
    "corr_df = pearson_correlation(df, numeric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6871cca7-f2ea-49b2-bf37-8a54d28e141d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAP_SOCIAL</th>\n",
       "      <th>ano_cadastro</th>\n",
       "      <th>mes_cadastro</th>\n",
       "      <th>LON</th>\n",
       "      <th>LAT</th>\n",
       "      <th>renda_per_capita</th>\n",
       "      <th>PRODUTO_INTERNO_BRUTO_A_PREOS_CORRENTES_R_1000</th>\n",
       "      <th>PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORRENTES_R_100</th>\n",
       "      <th>IDHM_2010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CAP_SOCIAL</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>6.401356e-07</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>-0.000491</td>\n",
       "      <td>-0.000922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ano_cadastro</th>\n",
       "      <td>1.415190e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.050614</td>\n",
       "      <td>-0.025593</td>\n",
       "      <td>-3.803530e-02</td>\n",
       "      <td>0.014278</td>\n",
       "      <td>-0.012613</td>\n",
       "      <td>-0.005944</td>\n",
       "      <td>0.046667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mes_cadastro</th>\n",
       "      <td>4.653095e-04</td>\n",
       "      <td>-0.050614</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014502</td>\n",
       "      <td>2.530920e-03</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.014670</td>\n",
       "      <td>0.022993</td>\n",
       "      <td>0.008726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LON</th>\n",
       "      <td>3.154417e-04</td>\n",
       "      <td>-0.025593</td>\n",
       "      <td>0.014502</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.535273e-01</td>\n",
       "      <td>-0.097565</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>-0.119251</td>\n",
       "      <td>-0.196605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAT</th>\n",
       "      <td>6.401356e-07</td>\n",
       "      <td>-0.038035</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.353527</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-0.205726</td>\n",
       "      <td>-0.181833</td>\n",
       "      <td>-0.247140</td>\n",
       "      <td>-0.470019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renda_per_capita</th>\n",
       "      <td>-1.198429e-04</td>\n",
       "      <td>0.014278</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>-0.097565</td>\n",
       "      <td>-2.057262e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.217996</td>\n",
       "      <td>0.168798</td>\n",
       "      <td>0.404073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRODUTO_INTERNO_BRUTO_A_PREOS_CORRENTES_R_1000</th>\n",
       "      <td>-1.005979e-04</td>\n",
       "      <td>-0.012613</td>\n",
       "      <td>0.014670</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>-1.818333e-01</td>\n",
       "      <td>0.217996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.330609</td>\n",
       "      <td>0.378416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORRENTES_R_100</th>\n",
       "      <td>-4.914107e-04</td>\n",
       "      <td>-0.005944</td>\n",
       "      <td>0.022993</td>\n",
       "      <td>-0.119251</td>\n",
       "      <td>-2.471400e-01</td>\n",
       "      <td>0.168798</td>\n",
       "      <td>0.330609</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.353570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDHM_2010</th>\n",
       "      <td>-9.217829e-04</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>-0.196605</td>\n",
       "      <td>-4.700186e-01</td>\n",
       "      <td>0.404073</td>\n",
       "      <td>0.378416</td>\n",
       "      <td>0.353570</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      CAP_SOCIAL  \\\n",
       "CAP_SOCIAL                                          1.000000e+00   \n",
       "ano_cadastro                                        1.415190e-03   \n",
       "mes_cadastro                                        4.653095e-04   \n",
       "LON                                                 3.154417e-04   \n",
       "LAT                                                 6.401356e-07   \n",
       "renda_per_capita                                   -1.198429e-04   \n",
       "PRODUTO_INTERNO_BRUTO_A_PREOS_CORRENTES_R_1000     -1.005979e-04   \n",
       "PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORREN... -4.914107e-04   \n",
       "IDHM_2010                                          -9.217829e-04   \n",
       "\n",
       "                                                    ano_cadastro  \\\n",
       "CAP_SOCIAL                                              0.001415   \n",
       "ano_cadastro                                            1.000000   \n",
       "mes_cadastro                                           -0.050614   \n",
       "LON                                                    -0.025593   \n",
       "LAT                                                    -0.038035   \n",
       "renda_per_capita                                        0.014278   \n",
       "PRODUTO_INTERNO_BRUTO_A_PREOS_CORRENTES_R_1000         -0.012613   \n",
       "PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORREN...     -0.005944   \n",
       "IDHM_2010                                               0.046667   \n",
       "\n",
       "                                                    mes_cadastro       LON  \\\n",
       "CAP_SOCIAL                                              0.000465  0.000315   \n",
       "ano_cadastro                                           -0.050614 -0.025593   \n",
       "mes_cadastro                                            1.000000  0.014502   \n",
       "LON                                                     0.014502  1.000000   \n",
       "LAT                                                     0.002531  0.353527   \n",
       "renda_per_capita                                        0.001000 -0.097565   \n",
       "PRODUTO_INTERNO_BRUTO_A_PREOS_CORRENTES_R_1000          0.014670  0.003039   \n",
       "PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORREN...      0.022993 -0.119251   \n",
       "IDHM_2010                                               0.008726 -0.196605   \n",
       "\n",
       "                                                             LAT  \\\n",
       "CAP_SOCIAL                                          6.401356e-07   \n",
       "ano_cadastro                                       -3.803530e-02   \n",
       "mes_cadastro                                        2.530920e-03   \n",
       "LON                                                 3.535273e-01   \n",
       "LAT                                                 1.000000e+00   \n",
       "renda_per_capita                                   -2.057262e-01   \n",
       "PRODUTO_INTERNO_BRUTO_A_PREOS_CORRENTES_R_1000     -1.818333e-01   \n",
       "PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORREN... -2.471400e-01   \n",
       "IDHM_2010                                          -4.700186e-01   \n",
       "\n",
       "                                                    renda_per_capita  \\\n",
       "CAP_SOCIAL                                                 -0.000120   \n",
       "ano_cadastro                                                0.014278   \n",
       "mes_cadastro                                                0.001000   \n",
       "LON                                                        -0.097565   \n",
       "LAT                                                        -0.205726   \n",
       "renda_per_capita                                            1.000000   \n",
       "PRODUTO_INTERNO_BRUTO_A_PREOS_CORRENTES_R_1000              0.217996   \n",
       "PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORREN...          0.168798   \n",
       "IDHM_2010                                                   0.404073   \n",
       "\n",
       "                                                    PRODUTO_INTERNO_BRUTO_A_PREOS_CORRENTES_R_1000  \\\n",
       "CAP_SOCIAL                                                                               -0.000101   \n",
       "ano_cadastro                                                                             -0.012613   \n",
       "mes_cadastro                                                                              0.014670   \n",
       "LON                                                                                       0.003039   \n",
       "LAT                                                                                      -0.181833   \n",
       "renda_per_capita                                                                          0.217996   \n",
       "PRODUTO_INTERNO_BRUTO_A_PREOS_CORRENTES_R_1000                                            1.000000   \n",
       "PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORREN...                                        0.330609   \n",
       "IDHM_2010                                                                                 0.378416   \n",
       "\n",
       "                                                    PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORRENTES_R_100  \\\n",
       "CAP_SOCIAL                                                                                  -0.000491          \n",
       "ano_cadastro                                                                                -0.005944          \n",
       "mes_cadastro                                                                                 0.022993          \n",
       "LON                                                                                         -0.119251          \n",
       "LAT                                                                                         -0.247140          \n",
       "renda_per_capita                                                                             0.168798          \n",
       "PRODUTO_INTERNO_BRUTO_A_PREOS_CORRENTES_R_1000                                               0.330609          \n",
       "PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORREN...                                           1.000000          \n",
       "IDHM_2010                                                                                    0.353570          \n",
       "\n",
       "                                                    IDHM_2010  \n",
       "CAP_SOCIAL                                          -0.000922  \n",
       "ano_cadastro                                         0.046667  \n",
       "mes_cadastro                                         0.008726  \n",
       "LON                                                 -0.196605  \n",
       "LAT                                                 -0.470019  \n",
       "renda_per_capita                                     0.404073  \n",
       "PRODUTO_INTERNO_BRUTO_A_PREOS_CORRENTES_R_1000       0.378416  \n",
       "PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORREN...   0.353570  \n",
       "IDHM_2010                                            1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad687d72-8995-48cb-b9fd-fbefe4a77ddc",
   "metadata": {},
   "source": [
    "## Variance Threshold Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73e6d90f-edfe-4648-a35e-cd1379383dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas selecionadas com variância acima do limiar: ['CAP_SOCIAL', 'ano_cadastro', 'mes_cadastro', 'LON', 'LAT', 'renda_per_capita', 'PRODUTO_INTERNO_BRUTO_A_PREOS_CORRENTES_R_1000', 'PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORRENTES_R_100']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CAP_SOCIAL',\n",
       " 'ano_cadastro',\n",
       " 'mes_cadastro',\n",
       " 'LON',\n",
       " 'LAT',\n",
       " 'renda_per_capita',\n",
       " 'PRODUTO_INTERNO_BRUTO_A_PREOS_CORRENTES_R_1000',\n",
       " 'PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORRENTES_R_100']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variance Threshold Selector\n",
    "response_col = 'CAP_SOCIAL'\n",
    "numeric_features = [t[0] for t in df.dtypes if t[1] in ('int', 'double', 'float', 'long')]\n",
    "selected_features_variance = variance_threshold_selector(df, numeric_features)\n",
    "selected_features_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f63e0b3-4310-46f8-9bcc-fdb31f6b5ce0",
   "metadata": {},
   "source": [
    "## RFormula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ced59396-d1d9-46b6-a4f7-85c614981a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas significativas com base na importância do RandomForest:\n",
      "Feature: TIPO_LOUGRADOURO, Importance: 0.03138327609303246\n",
      "Feature: UF, Importance: 0.024775483506614855\n",
      "Feature: SEXO_PROB, Importance: 0.01660597854927476\n",
      "Feature: ATIVIDADE_COM_MAIOR_VALOR_ADICIONADO_BRUTO, Importance: 2.5326721948599455e-05\n",
      "Feature: CNAE, Importance: 4.2959503610569925e-06\n",
      "Feature: mes_cadastro, Importance: 8.225645851901859e-11\n",
      "Feature: PROVEDOR, Importance: 4.859919195163692e-13\n",
      "Feature: DDD1, Importance: 0.0\n",
      "Feature: TIPO_TELEFONE_FINAL, Importance: 0.0\n",
      "Feature: OPERADORA, Importance: 0.0\n",
      "Feature: MUNICIPIO, Importance: 0.0\n",
      "Feature: ATIVIDADE_COM_SEGUNDO_MAIOR_VALOR_ADICIONADO_BRUTO, Importance: 0.0\n",
      "Feature: CAP_SOCIAL, Importance: 0.0\n",
      "Feature: ano_cadastro, Importance: 0.0\n",
      "Feature: LON, Importance: 0.0\n",
      "Feature: LAT, Importance: 0.0\n",
      "Feature: renda_per_capita, Importance: 0.0\n",
      "Feature: PRODUTO_INTERNO_BRUTO_A_PREOS_CORRENTES_R_1000, Importance: 0.0\n",
      "Feature: PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORRENTES_R_100, Importance: 0.0\n",
      "Feature: IDHM_2010, Importance: 0.0\n",
      "Root Mean Squared Error (RMSE) no conjunto de teste: 4085085.1118489276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('TIPO_LOUGRADOURO', 0.03138327609303246),\n",
       " ('UF', 0.024775483506614855),\n",
       " ('SEXO_PROB', 0.01660597854927476),\n",
       " ('ATIVIDADE_COM_MAIOR_VALOR_ADICIONADO_BRUTO', 2.5326721948599455e-05),\n",
       " ('CNAE', 4.2959503610569925e-06),\n",
       " ('mes_cadastro', 8.225645851901859e-11),\n",
       " ('PROVEDOR', 4.859919195163692e-13),\n",
       " ('DDD1', 0.0),\n",
       " ('TIPO_TELEFONE_FINAL', 0.0),\n",
       " ('OPERADORA', 0.0),\n",
       " ('MUNICIPIO', 0.0),\n",
       " ('ATIVIDADE_COM_SEGUNDO_MAIOR_VALOR_ADICIONADO_BRUTO', 0.0),\n",
       " ('CAP_SOCIAL', 0.0),\n",
       " ('ano_cadastro', 0.0),\n",
       " ('LON', 0.0),\n",
       " ('LAT', 0.0),\n",
       " ('renda_per_capita', 0.0),\n",
       " ('PRODUTO_INTERNO_BRUTO_A_PREOS_CORRENTES_R_1000', 0.0),\n",
       " ('PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORRENTES_R_100', 0.0),\n",
       " ('IDHM_2010', 0.0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RFormula\n",
    "response_col = 'CAP_SOCIAL'\n",
    "categorical_cols = [\"SEXO_PROB\", \"CNAE\", \"TIPO_LOUGRADOURO\", \n",
    "                    \"PROVEDOR\", \"DDD1\", \"TIPO_TELEFONE_FINAL\", \"OPERADORA\", \"MUNICIPIO\", \"UF\",\n",
    "                    \"ATIVIDADE_COM_MAIOR_VALOR_ADICIONADO_BRUTO\", \"ATIVIDADE_COM_SEGUNDO_MAIOR_VALOR_ADICIONADO_BRUTO\"]\n",
    "r_formula_df = r_formula_with_feature_importance(df, categorical_cols, numeric_features, response_col)\n",
    "r_formula_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12bdaa0-5a8f-4e5d-afd5-aed8ea16a684",
   "metadata": {},
   "source": [
    "## VectorSlicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d91f664-1583-4bec-b08e-f659e9aa086b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|selectedFeatures        |\n",
      "+------------------------+\n",
      "|[0.0,18.0,1.0,14.0,0.0] |\n",
      "|[0.0,42.0,1.0,8.0,0.0]  |\n",
      "|[0.0,20.0,1.0,5.0,0.0]  |\n",
      "|[0.0,56.0,17.0,6.0,0.0] |\n",
      "|[0.0,61.0,1.0,21.0,0.0] |\n",
      "|[0.0,20.0,1.0,51.0,0.0] |\n",
      "|[0.0,168.0,1.0,1.0,0.0] |\n",
      "|[1.0,102.0,1.0,21.0,0.0]|\n",
      "|[0.0,5.0,0.0,2.0,0.0]   |\n",
      "|[0.0,216.0,1.0,20.0,0.0]|\n",
      "|[1.0,88.0,3.0,14.0,0.0] |\n",
      "|[0.0,21.0,5.0,6.0,0.0]  |\n",
      "|[0.0,6.0,0.0,45.0,0.0]  |\n",
      "|(5,[1,2],[21.0,6.0])    |\n",
      "|[1.0,4.0,0.0,1.0,0.0]   |\n",
      "|[1.0,0.0,4.0,22.0,0.0]  |\n",
      "|[0.0,40.0,3.0,14.0,0.0] |\n",
      "|[0.0,82.0,4.0,36.0,0.0] |\n",
      "|[0.0,115.0,4.0,24.0,0.0]|\n",
      "|[1.0,295.0,3.0,21.0,0.0]|\n",
      "+------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Nomes das colunas selecionadas: ['SEXO_PROB_index', 'CNAE_index', 'PROVEDOR_index', 'DDD1_index', 'TIPO_TELEFONE_FINAL_index']\n"
     ]
    }
   ],
   "source": [
    "# VectorSlicer\n",
    "response_col = 'CAP_SOCIAL'\n",
    "categorical_cols = [\"SEXO_PROB\", \"CNAE\", \"TIPO_LOUGRADOURO\", \n",
    "                    \"PROVEDOR\", \"DDD1\", \"TIPO_TELEFONE_FINAL\", \"OPERADORA\", \"MUNICIPIO\", \"UF\",\n",
    "                    \"ATIVIDADE_COM_MAIOR_VALOR_ADICIONADO_BRUTO\", \"ATIVIDADE_COM_SEGUNDO_MAIOR_VALOR_ADICIONADO_BRUTO\"]\n",
    "numeric_features = [t[0] for t in df.dtypes if t[1] in ('int', 'double', 'float', 'long')]\n",
    "\n",
    "vector_resp = vector_slicer_function(df, categorical_cols, numeric_features, response_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412d7115-4003-45f4-afe7-0468b891f2c7",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c906edc8-273c-456e-b966-a507e0cddca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas significativas com base na importância do RandomForestRegressor:\n",
      "['CNAE_index', 'PROVEDOR_index', 'ano_cadastro', 'MUNICIPIO_index', 'TIPO_TELEFONE_FINAL_index']\n"
     ]
    }
   ],
   "source": [
    "response_col = 'CAP_SOCIAL'\n",
    "categorical_cols = [\"SEXO_PROB\", \"CNAE\", \"TIPO_LOUGRADOURO\", \n",
    "                    \"PROVEDOR\", \"DDD1\", \"TIPO_TELEFONE_FINAL\", \"OPERADORA\", \"MUNICIPIO\", \"UF\",\n",
    "                    \"ATIVIDADE_COM_MAIOR_VALOR_ADICIONADO_BRUTO\", \"ATIVIDADE_COM_SEGUNDO_MAIOR_VALOR_ADICIONADO_BRUTO\"]\n",
    "numeric_features = [t[0] for t in df.dtypes if t[1] in ('int', 'double', 'float', 'long')]\n",
    "significant_columns_rf_reg = feature_importance_rf_reg(df, categorical_cols, numeric_features, response_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0d01d47-0d2b-4e1f-92a1-b5dbb3b0ea76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNAE_index',\n",
       " 'PROVEDOR_index',\n",
       " 'ano_cadastro',\n",
       " 'MUNICIPIO_index',\n",
       " 'TIPO_TELEFONE_FINAL_index']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significant_columns_rf_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f48233-f389-4a24-a54b-c8d7098bd8ce",
   "metadata": {},
   "source": [
    "## Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80dcccdb-d378-45aa-9e9c-6f6670e41394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas selecionadas: ['CNAE_index', 'TIPO_TELEFONE_FINAL_index', 'OPERADORA_index', 'DDD1_index', 'ano_cadastro', 'IDHM_2010', 'ATIVIDADE_COM_SEGUNDO_MAIOR_VALOR_ADICIONADO_BRUTO_index', 'UF_index', 'ATIVIDADE_COM_MAIOR_VALOR_ADICIONADO_BRUTO_index', 'PRODUTO_INTERNO_BRUTO_PER_CAPITA_A_PREOS_CORRENTES_R_100']\n"
     ]
    }
   ],
   "source": [
    "response_col = 'CAP_SOCIAL'\n",
    "categorical_cols = [\"SEXO_PROB\", \"CNAE\", \"TIPO_LOUGRADOURO\", \n",
    "                    \"PROVEDOR\", \"DDD1\", \"TIPO_TELEFONE_FINAL\", \"OPERADORA\", \"MUNICIPIO\", \"UF\",\n",
    "                    \"ATIVIDADE_COM_MAIOR_VALOR_ADICIONADO_BRUTO\", \"ATIVIDADE_COM_SEGUNDO_MAIOR_VALOR_ADICIONADO_BRUTO\"]\n",
    "numeric_features = [t[0] for t in df.dtypes if t[1] in ('int', 'double', 'float', 'long')]\n",
    "\n",
    "selected_features = univariate_feature_selector_var_num(df, categorical_cols, numeric_features, response_col, selectionThreshold=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a311bea4-5720-481e-83ce-a3159887803a",
   "metadata": {},
   "source": [
    "## Regressão "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e51ff17b-1179-4f57-85f4-ca3c103547d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_linear_reg(df, categorical_cols, numeric_features, response_col):\n",
    "    # Remover a variável dependente das listas de variáveis preditoras\n",
    "    if response_col in categorical_cols:\n",
    "        categorical_cols.remove(response_col)\n",
    "    if response_col in numeric_features:\n",
    "        numeric_features.remove(response_col)\n",
    "\n",
    "    # Indexação das colunas categóricas\n",
    "    indexers = [\n",
    "        StringIndexer(inputCol=col, outputCol=col + \"_index\", handleInvalid=\"skip\")\n",
    "        for col in categorical_cols\n",
    "    ]\n",
    "\n",
    "    # Assembler para criar o vetor de features\n",
    "    input_cols = [col + \"_index\" for col in categorical_cols] + numeric_features\n",
    "    assembler = VectorAssembler(inputCols=input_cols, outputCol=\"features\")\n",
    "\n",
    "    # Pipeline para processar indexação e assembler\n",
    "    pipeline = Pipeline(stages=indexers + [assembler])\n",
    "    df_transformed = pipeline.fit(df).transform(df)\n",
    "\n",
    "    # Configurando a Regressão Linear com ElasticNet (regularização combinando L1 e L2)\n",
    "    lr = LinearRegression(featuresCol=\"features\", labelCol=response_col, elasticNetParam=0.5)\n",
    "    lr_model = lr.fit(df_transformed)\n",
    "\n",
    "    # Obtendo os coeficientes das features\n",
    "    coefficients = lr_model.coefficients.toArray()\n",
    "\n",
    "    # Vinculando coeficientes com os nomes das colunas\n",
    "    important_features = sorted(zip(input_cols, coefficients), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "    # Definindo um threshold para selecionar as colunas mais importantes\n",
    "    threshold = 0.05  # Ajuste conforme necessário\n",
    "    significant_columns = [name for name, coef in important_features if abs(coef) > threshold]\n",
    "\n",
    "    print(\"Colunas significativas com base na Regressão Linear ElasticNet:\")\n",
    "    print(significant_columns)\n",
    "    \n",
    "    return significant_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "255f9436-b538-4e61-a027-9bc49a431b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas significativas com base na Regressão Linear ElasticNet:\n",
      "['IDHM_2010', 'TIPO_TELEFONE_FINAL_index', 'SEXO_PROB_index', 'ano_cadastro', 'ATIVIDADE_COM_MAIOR_VALOR_ADICIONADO_BRUTO_index', 'ATIVIDADE_COM_SEGUNDO_MAIOR_VALOR_ADICIONADO_BRUTO_index', 'UF_index', 'mes_cadastro', 'OPERADORA_index', 'DDD1_index', 'LON', 'CNAE_index', 'TIPO_LOUGRADOURO_index', 'LAT', 'PROVEDOR_index', 'MUNICIPIO_index', 'renda_per_capita']\n"
     ]
    }
   ],
   "source": [
    "# Chamando a função para regressão linear\n",
    "response_col = 'CAP_SOCIAL'\n",
    "categorical_cols = [\"SEXO_PROB\", \"CNAE\", \"TIPO_LOUGRADOURO\", \n",
    "                    \"PROVEDOR\", \"DDD1\", \"TIPO_TELEFONE_FINAL\", \"OPERADORA\", \"MUNICIPIO\", \"UF\",\n",
    "                    \"ATIVIDADE_COM_MAIOR_VALOR_ADICIONADO_BRUTO\", \"ATIVIDADE_COM_SEGUNDO_MAIOR_VALOR_ADICIONADO_BRUTO\"]\n",
    "numeric_features = [t[0] for t in df.dtypes if t[1] in ('int', 'double', 'float', 'long')]\n",
    "significant_columns_linear = feature_importance_linear_reg(df, categorical_cols, numeric_features, response_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5f817c-d348-49a8-a91b-93af1ea49dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
