{"cells": [{"cell_type": "code", "execution_count": 1, "id": "d2d83c22-ec5e-425e-85fc-97612a75bbc9", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Requirement already satisfied: google-cloud-storage in /opt/conda/miniconda3/lib/python3.10/site-packages (2.5.0)\nRequirement already satisfied: requests in /opt/conda/miniconda3/lib/python3.10/site-packages (2.28.2)\nRequirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/miniconda3/lib/python3.10/site-packages (from google-cloud-storage) (2.27.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/miniconda3/lib/python3.10/site-packages (from google-cloud-storage) (2.16.1)\nRequirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/miniconda3/lib/python3.10/site-packages (from google-cloud-storage) (2.4.1)\nRequirement already satisfied: google-resumable-media>=2.3.2 in /opt/conda/miniconda3/lib/python3.10/site-packages (from google-cloud-storage) (2.7.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/miniconda3/lib/python3.10/site-packages (from requests) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/miniconda3/lib/python3.10/site-packages (from requests) (3.6)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/miniconda3/lib/python3.10/site-packages (from requests) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/miniconda3/lib/python3.10/site-packages (from requests) (2023.11.17)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/miniconda3/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.62.0)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /opt/conda/miniconda3/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (4.21.12)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/miniconda3/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (5.3.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/miniconda3/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/miniconda3/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.9)\nRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/miniconda3/lib/python3.10/site-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.1.2)\nRequirement already satisfied: cffi>=1.0.0 in /opt/conda/miniconda3/lib/python3.10/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media>=2.3.2->google-cloud-storage) (1.16.0)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/miniconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.5.1)\nRequirement already satisfied: pycparser in /opt/conda/miniconda3/lib/python3.10/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media>=2.3.2->google-cloud-storage) (2.21)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"}], "source": "pip install google-cloud-storage requests"}, {"cell_type": "code", "execution_count": 20, "id": "3c362e54-0617-4404-a50a-0df3cdf97a4c", "metadata": {}, "outputs": [], "source": "import logging\nfrom google.cloud import storage\nimport requests\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom datetime import datetime, timedelta\nimport gcsfs\nimport zipfile\nfrom io import BytesIO\nfrom pyspark.sql import SparkSession\nimport zipfile\nimport io\nimport gcsfs"}, {"cell_type": "markdown", "id": "23cf39de-dd54-401e-a179-dbcc95d6fa28", "metadata": {}, "source": "# Downlaod dos arquivos para o bucket"}, {"cell_type": "code", "execution_count": 14, "id": "1d369df1-3a73-45b9-81ba-76dc77a2fdc4", "metadata": {}, "outputs": [], "source": "class ReceitaCNPJApiGCP:\n    \"\"\"\n    Classe para interagir com a API de Dados Abertos da Receita Federal e salvar diretamente no Google Cloud Storage (GCS).\n\n    Esta classe facilita a obten\u00e7\u00e3o de dados relacionados a CNPJs e o armazenamento desses dados no GCS, implementando funcionalidades\n    para verificar a atualiza\u00e7\u00e3o dos dados, realizar tentativas de download com intervalos de espera e executar downloads de forma\n    ass\u00edncrona utilizando ThreadPoolExecutor.\n\n    Atributos:\n        BASE_URL (str): URL base para a API de Dados Abertos da Receita Federal.\n        bucket_name (str): Nome do bucket no Google Cloud Storage onde os arquivos ser\u00e3o salvos.\n        data_update (bool): Determina se a fun\u00e7\u00e3o deve verificar se os dados foram atualizados nos \u00faltimos 30 dias.\n        max_attempts (int): N\u00famero m\u00e1ximo de tentativas de download.\n        wait_time (int): Tempo de espera entre tentativas em segundos.\n        logger (Logger): Logger para registrar atividades e erros.\n        storage_client (Client): Cliente do Google Cloud Storage para intera\u00e7\u00e3o com o GCS.\n\n    M\u00e9todos:\n        __init__(self, bucket_name, data_update=True, max_attempts=15, wait_time=150):\n            Inicializa a classe com configura\u00e7\u00f5es espec\u00edficas para intera\u00e7\u00e3o com a API e o GCS.\n\n        get_last_update_date(self):\n            Verifica e retorna a \u00faltima data de atualiza\u00e7\u00e3o dos dados na API da Receita Federal.\n\n        should_update_data(self):\n            Avalia se os dados necessitam ser atualizados com base na \u00faltima data de atualiza\u00e7\u00e3o.\n\n        lista_urls_receita(self, *prefixes):\n            Gera uma lista de URLs para download com base nos prefixos de arquivo especificados.\n\n        download_and_upload_to_gcs(self, url, destination_blob_name):\n            Realiza o download de um arquivo da URL especificada e o salva diretamente no bucket do GCS.\n\n        download_files_concurrently(self, urls):\n            Utiliza ThreadPoolExecutor para baixar arquivos de uma lista de URLs fornecida de forma ass\u00edncrona.\n    \"\"\"\n\n    BASE_URL = \"https://dadosabertos.rfb.gov.br/CNPJ\"\n    FILE_PREFIXES = ['Estabelecimentos', 'Municipios', 'Simples', 'Empresas', 'Cnaes', 'Socios', 'Naturezas', 'Qualificacoes', 'Paises', 'Motivos']\n\n    def __init__(self, bucket_name, data_update=True, max_attempts=15, wait_time=150):\n        \"\"\"\n        Inicializa a classe com configura\u00e7\u00f5es para intera\u00e7\u00e3o com a API da Receita Federal e o Google Cloud Storage.\n\n        Par\u00e2metros:\n            bucket_name (str): Nome do bucket no GCS onde os arquivos ser\u00e3o salvos.\n            data_update (bool): Se True, verifica se os dados foram atualizados nos \u00faltimos 30 dias antes de baixar.\n            max_attempts (int): N\u00famero m\u00e1ximo de tentativas de download para cada arquivo.\n            wait_time (int): Tempo de espera (em segundos) entre as tentativas de download.\n        \"\"\"\n        self.bucket_name = bucket_name\n        self.data_update = data_update\n        self.max_attempts = max_attempts\n        self.wait_time = wait_time\n        self.logger = logging.getLogger(__name__)\n        logging.basicConfig(level=logging.INFO)\n        self.storage_client = storage.Client()\n\n    def get_last_update_date(self):\n        \"\"\"\n        Consulta a API da Receita Federal para determinar a \u00faltima data de atualiza\u00e7\u00e3o dos dados dispon\u00edveis.\n\n        Retorna:\n            datetime.date: A \u00faltima data de atualiza\u00e7\u00e3o dos dados, ou None se n\u00e3o puder ser determinada.\n        \"\"\"\n        response = requests.get(self.BASE_URL)\n        if response.status_code == 200:\n            last_update_date = datetime.today().date()  # Placeholder para a data real\n            return last_update_date\n        else:\n            self.logger.error(\"N\u00e3o foi poss\u00edvel verificar a data da \u00faltima atualiza\u00e7\u00e3o.\")\n            return None\n\n    def should_update_data(self):\n        \"\"\"\n        Determina se \u00e9 necess\u00e1rio atualizar os dados com base na \u00faltima data de atualiza\u00e7\u00e3o.\n\n        Retorna:\n            bool: True se os dados precisam ser atualizados, False caso contr\u00e1rio.\n        \"\"\"\n        if not self.data_update:\n            return True\n        last_update_date = self.get_last_update_date()\n        if last_update_date and (datetime.today().date() - last_update_date <= timedelta(days=30)):\n            return True\n        else:\n            return False\n\n    def lista_urls_receita(self, *prefixes):\n        \"\"\"\n        Gera uma lista de URLs para download com base nos prefixos fornecidos. As URLs s\u00e3o \n        determinadas com base nos prefixos de arquivo conhecidos. Se nenhum prefixo for \n        fornecido, o m\u00e9todo gerar\u00e1 URLs para todos os tipos de arquivos conhecidos.\n\n        Args:\n            *prefixes (str): Prefixos de arquivos para os quais as URLs ser\u00e3o geradas.\n\n        Returns:\n            list: Lista de URLs completas para os arquivos correspondentes aos prefixos.\n        \"\"\"\n        urls = []\n\n        # Usa todos os prefixos de arquivo conhecidos se nenhum prefixo espec\u00edfico for fornecido\n        if not prefixes:\n            prefixes = self.FILE_PREFIXES\n\n        for prefix in prefixes:\n            # Para prefixos espec\u00edficos que sabemos terem apenas um arquivo associado\n            if prefix in ['Municipios', 'Cnaes', 'Naturezas', 'Simples', 'Qualificacoes', 'Paises', 'Motivos']:\n                urls.append(f\"{self.BASE_URL}/{prefix}.zip\")\n            # Para prefixos que potencialmente t\u00eam m\u00faltiplos arquivos (identificados por \u00edndices de 0 a 9)\n            elif prefix in ['Estabelecimentos', 'Empresas', 'Socios']:\n                for i in range(10):  # Ajuste o range se necess\u00e1rio\n                    urls.append(f\"{self.BASE_URL}/{prefix}{i}.zip\")\n            else:\n                self.logger.warning(f\"Prefixo '{prefix}' n\u00e3o reconhecido. Verifique a lista de prefixos v\u00e1lidos.\")\n\n        return urls\n\n    def download_and_upload_to_gcs(self, url, destination_blob_name):\n        \"\"\"\n        Baixa um arquivo da URL especificada e o salva diretamente em um bucket do GCS.\n\n        Par\u00e2metros:\n            url (str): URL do arquivo para download.\n            destination_blob_name (str): Localiza\u00e7\u00e3o (caminho/nome) no bucket do GCS onde o arquivo ser\u00e1 salvo.\n        \"\"\"\n        for attempt in range(self.max_attempts):\n            try:\n                response = requests.get(url, stream=True)\n                response.raise_for_status()\n                bucket = self.storage_client.bucket(self.bucket_name)\n                blob = bucket.blob(destination_blob_name)\n                blob.upload_from_string(response.content)\n                self.logger.info(f\"Arquivo {url} baixado e salvo em {destination_blob_name} com sucesso.\")\n                return\n            except requests.RequestException as e:\n                self.logger.error(f\"Tentativa {attempt + 1} de download falhou: {e}\")\n                if attempt < self.max_attempts - 1:\n                    time.sleep(self.wait_time)\n                else:\n                    self.logger.error(f\"Erro ao salvar o arquivo {destination_blob_name}: {e}\")\n\n    def download_files_concurrently(self, urls, prefix):\n        \"\"\"\n        Baixa arquivos de forma ass\u00edncrona a partir de uma lista de URLs e os salva no GCS.\n\n        Par\u00e2metros:\n            urls (list[str]): Lista de URLs dos arquivos a serem baixados.\n            prefix (str): Prefixo do diret\u00f3rio para salvar os arquivos no bucket.\n        \"\"\"\n        if self.should_update_data():\n            with ThreadPoolExecutor(max_workers=5) as executor:\n                # Certifique-se de usar prefix como um \u00fanico diret\u00f3rio, n\u00e3o a primeira letra\n                future_to_url = {executor.submit(self.download_and_upload_to_gcs, url, f'{prefix}/' + url.split('/')[-1]): url for url in urls}\n                for future in as_completed(future_to_url):\n                    url = future_to_url[future]\n                    try:\n                        future.result()\n                    except Exception as e:\n                        self.logger.error(f\"Erro ao processar {url}: {e}\")\n        else:\n            self.logger.info(\"Dados n\u00e3o necessitam atualiza\u00e7\u00e3o.\")"}, {"cell_type": "code", "execution_count": null, "id": "4252df33-c4fd-4123-bc62-fd696e0cf077", "metadata": {}, "outputs": [], "source": "# Exemplo de uso\nif __name__ == \"__main__\":\n    bucket_name = \"projeto-receita-federal-deszipados\"\n    api = ReceitaCNPJApiGCP(bucket_name=bucket_name, data_update=True, max_attempts=15, wait_time=150)\n    prefix = prefix = ['Simples']\n    for i in prefix:\n        urls = api.lista_urls_receita(f'{i}')\n        api.download_files_concurrently(urls, f'{i}')"}, {"cell_type": "code", "execution_count": 5, "id": "5bd6ed21-f7dd-467e-b9e0-8078f319be09", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "INFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Municipios.zip baixado e salvo em Municipios/Municipios.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Cnaes.zip baixado e salvo em Cnaes/Cnaes.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Naturezas.zip baixado e salvo em Naturezas/Naturezas.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Simples.zip baixado e salvo em Simples/Simples.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Qualificacoes.zip baixado e salvo em Qualificacoes/Qualificacoes.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Paises.zip baixado e salvo em Paises/Paises.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Motivos.zip baixado e salvo em Motivos/Motivos.zip com sucesso.\n"}], "source": "# Exemplo de uso\nif __name__ == \"__main__\":\n    bucket_name = \"projeto-dados-receita-federal\"\n    api = ReceitaCNPJApiGCP(bucket_name=bucket_name, data_update=True, max_attempts=15, wait_time=150)\n    prefix = prefix = ['Municipios', 'Cnaes', 'Naturezas', 'Simples', 'Qualificacoes', 'Paises', 'Motivos']\n    for i in prefix:\n        urls = api.lista_urls_receita(f'{i}')\n        api.download_files_concurrently(urls, f'{i}')"}, {"cell_type": "code", "execution_count": 9, "id": "2cf3bf46-6b75-48cb-95dd-373bf9fa299e", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "INFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Socios4.zip baixado e salvo em Socios/Socios4.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Socios3.zip baixado e salvo em Socios/Socios3.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Socios2.zip baixado e salvo em Socios/Socios2.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Socios1.zip baixado e salvo em Socios/Socios1.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Socios5.zip baixado e salvo em Socios/Socios5.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Socios6.zip baixado e salvo em Socios/Socios6.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Socios7.zip baixado e salvo em Socios/Socios7.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Socios8.zip baixado e salvo em Socios/Socios8.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Socios0.zip baixado e salvo em Socios/Socios0.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Socios9.zip baixado e salvo em Socios/Socios9.zip com sucesso.\n"}], "source": "# Exemplo de uso\nif __name__ == \"__main__\":\n    bucket_name = \"projeto-dados-receita-federal\"\n    api = ReceitaCNPJApiGCP(bucket_name=bucket_name, data_update=True, max_attempts=15, wait_time=150)\n    prefix = prefix = ['Socios']\n    for i in prefix:\n        urls = api.lista_urls_receita(f'{i}')\n        api.download_files_concurrently(urls, f'{i}')"}, {"cell_type": "code", "execution_count": null, "id": "cce409cc-ade1-4e6d-b5bd-41ba6812cf22", "metadata": {}, "outputs": [], "source": "# Exemplo de uso\nif __name__ == \"__main__\":\n    bucket_name = \"projeto-dados-receita-federal\"\n    api = ReceitaCNPJApiGCP(bucket_name=bucket_name, data_update=True, max_attempts=15, wait_time=150)\n    prefix = prefix = ['Empresas']\n    for i in prefix:\n        urls = api.lista_urls_receita(f'{i}')\n        api.download_files_concurrently(urls, f'{i}')"}, {"cell_type": "code", "execution_count": 12, "id": "19ebe8fe-91d5-4ac8-8e87-c60faca0a806", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "INFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Estabelecimentos3.zip baixado e salvo em Estabelecimentos/Estabelecimentos3.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Estabelecimentos1.zip baixado e salvo em Estabelecimentos/Estabelecimentos1.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Estabelecimentos4.zip baixado e salvo em Estabelecimentos/Estabelecimentos4.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Estabelecimentos2.zip baixado e salvo em Estabelecimentos/Estabelecimentos2.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Estabelecimentos7.zip baixado e salvo em Estabelecimentos/Estabelecimentos7.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Estabelecimentos5.zip baixado e salvo em Estabelecimentos/Estabelecimentos5.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Estabelecimentos9.zip baixado e salvo em Estabelecimentos/Estabelecimentos9.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Estabelecimentos6.zip baixado e salvo em Estabelecimentos/Estabelecimentos6.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Estabelecimentos8.zip baixado e salvo em Estabelecimentos/Estabelecimentos8.zip com sucesso.\nINFO:__main__:Arquivo https://dadosabertos.rfb.gov.br/CNPJ/Estabelecimentos0.zip baixado e salvo em Estabelecimentos/Estabelecimentos0.zip com sucesso.\n"}], "source": "# Exemplo de uso\nif __name__ == \"__main__\":\n    bucket_name = \"projeto-dados-receita-federal\"\n    api = ReceitaCNPJApiGCP(bucket_name=bucket_name, data_update=True, max_attempts=15, wait_time=150)\n    prefix = prefix = ['Estabelecimentos']\n    for i in prefix:\n        urls = api.lista_urls_receita(f'{i}')\n        api.download_files_concurrently(urls, f'{i}')"}, {"cell_type": "markdown", "id": "b2313b3b-3cb4-4270-a343-656983371b50", "metadata": {}, "source": "# Deszip dos arquivos \u00fanicos"}, {"cell_type": "code", "execution_count": 15, "id": "958dd0ba-3de3-4209-9dbe-83abe204cc7b", "metadata": {}, "outputs": [], "source": "def extract_file_by_condition_from_zip_in_gcs(bucket_name, zip_file_path, output_path, condition_func=None):\n    \"\"\"\n    Extrai um arquivo baseado em uma condi\u00e7\u00e3o espec\u00edfica de um arquivo zip armazenado no GCS.\n    \"\"\"\n    # Inicializa o sistema de arquivos GCS\n    fs = gcsfs.GCSFileSystem()\n\n    # Caminho completo do arquivo zip no GCS\n    full_zip_file_path = f\"{bucket_name}/{zip_file_path}\"\n    \n    # L\u00ea o arquivo zip do GCS\n    with fs.open(full_zip_file_path, 'rb') as f:\n        with zipfile.ZipFile(BytesIO(f.read()), 'r') as z:\n            # Lista todos os arquivos no arquivo zip e aplica a condi\u00e7\u00e3o, se fornecida\n            file_list = z.namelist()\n            for file_name in file_list:\n                if condition_func is None or condition_func(file_name):\n                    # Extrai o arquivo para a mem\u00f3ria\n                    with z.open(file_name) as specific_file:\n                        data = specific_file.read()\n                        \n                        # Define o nome do arquivo de sa\u00edda (ajuste conforme necess\u00e1rio)\n                        output_file_name = file_name.split('/')[-1]\n\n                        # Salva o arquivo extra\u00eddo no GCS\n                        with fs.open(f\"{output_path}/{output_file_name}\", 'wb') as f_out:\n                            f_out.write(data)\n                    print(f\"File {file_name} extracted and saved to {output_path}\")\n                    break  # Remova ou ajuste conforme a necessidade de extrair mais arquivos\n            else:\n                print(\"No files found matching the condition.\")\n\ndef extract_files_by_prefixes_from_zips_in_gcs(bucket_name, prefixes, base_output_path, condition_func=None):\n    \"\"\"\n    Extrai arquivos baseados em uma condi\u00e7\u00e3o espec\u00edfica de v\u00e1rios arquivos zip armazenados no GCS,\n    cada um correspondendo a um prefixo na lista fornecida.\n    \"\"\"\n    for prefix in prefixes:\n        zip_file_path = f'{prefix}/{prefix}.zip'\n        # Constr\u00f3i o caminho de sa\u00edda diretamente usando o prefixo\n        output_path = f\"{base_output_path}/{prefix}/arquivo_deszipado\"\n        try:\n            extract_file_by_condition_from_zip_in_gcs(\n                bucket_name=bucket_name,\n                zip_file_path=zip_file_path,\n                output_path=output_path,\n                condition_func=condition_func\n            )\n            print(f\"Completed extraction for prefix: {prefix}\")\n        except Exception as e:\n            print(f\"Error extracting files for prefix {prefix}: {e}\")"}, {"cell_type": "code", "execution_count": 18, "id": "71d864d7-940e-48b3-9079-9358a6aed5c2", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "File F.K03200$W.SIMPLES.CSV.D40113 extracted and saved to projeto-dados-receita-federal/Simples/arquivo_deszipado\nCompleted extraction for prefix: Simples\n"}], "source": "# Configura\u00e7\u00e3o dos prefixos e chamada das fun\u00e7\u00f5es\nprefixes = ['Municipios', 'Cnaes', 'Naturezas', 'Qualificacoes', 'Paises', 'Motivos','Simples']\nbucket_name = 'projeto-dados-receita-federal'\nbase_output_path = 'projeto-dados-receita-federal'  # Caminho base ajustado\n\n# Executa a extra\u00e7\u00e3o\nextract_files_by_prefixes_from_zips_in_gcs(\n    bucket_name=bucket_name,\n    prefixes=prefixes,\n    base_output_path=base_output_path,\n    condition_func=None  # Pode ser substitu\u00eddo por uma fun\u00e7\u00e3o espec\u00edfica se necess\u00e1rio\n)"}, {"cell_type": "markdown", "id": "f3c2015a-8a35-4e64-bde3-bd79b9a8e3fa", "metadata": {}, "source": "# Deszipando de forma distribuida "}, {"cell_type": "code", "execution_count": 23, "id": "4662be2f-7413-4185-954e-73b81bd1c175", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Fun\u00e7\u00e3o para extrair arquivos de um zip e salvar no GCS\ndef extract_and_save_file(zip_bytes_io, file_name, gcs_output_path):\n    with zipfile.ZipFile(zip_bytes_io) as z:\n        with z.open(file_name) as specific_file:\n            data = specific_file.read()\n            # Escrever no GCS usando gcsfs\n            fs = gcsfs.GCSFileSystem()\n            with fs.open(gcs_output_path, 'wb') as f_out:\n                f_out.write(data)\n            print(f\"File {file_name} extracted and saved to {gcs_output_path}\")\n\n# Inicializa a sess\u00e3o do Spark\nspark = SparkSession.builder.appName(\"ExtractZipFiles\").getOrCreate()\n\n# Defini\u00e7\u00e3o de vari\u00e1veis\nbucket_name = 'projeto-dados-receita-federal'\nprefixes = ['Empresas']\n\n# RDD para processar arquivos\nfor prefix in prefixes:\n    for i in range(10):\n        zip_file_path = f'gs://{bucket_name}/{prefix}/{prefix}{i}.zip'\n        output_path = f'gs://{bucket_name}/{prefix}/arquivo_deszipado/'\n        \n        # L\u00ea o arquivo zip como bytes\n        rdd = spark.sparkContext.binaryFiles(zip_file_path)\n        \n        # Processa cada arquivo no zip\n        def process_zip_file(file_data):\n            zip_bytes_io = io.BytesIO(file_data[1])\n            with zipfile.ZipFile(zip_bytes_io, 'r') as z:\n                file_list = z.namelist()\n                for file_name in file_list:\n                    extract_and_save_file(zip_bytes_io, file_name, output_path + file_name)\n        \n        # Aplica a fun\u00e7\u00e3o a cada arquivo no RDD\n        rdd.foreach(process_zip_file)"}, {"cell_type": "code", "execution_count": null, "id": "7d708515-59da-4acc-a949-062be5d75c96", "metadata": {}, "outputs": [], "source": "# Defini\u00e7\u00e3o de vari\u00e1veis\nbucket_name = 'projeto-dados-receita-federal'\nprefixes = ['Socios']\n\n# RDD para processar arquivos\nfor prefix in prefixes:\n    for i in range(10):\n        zip_file_path = f'gs://{bucket_name}/{prefix}/{prefix}{i}.zip'\n        output_path = f'gs://{bucket_name}/{prefix}/arquivo_deszipado/'\n        \n        # L\u00ea o arquivo zip como bytes\n        rdd = spark.sparkContext.binaryFiles(zip_file_path)\n        \n        # Processa cada arquivo no zip\n        def process_zip_file(file_data):\n            zip_bytes_io = io.BytesIO(file_data[1])\n            with zipfile.ZipFile(zip_bytes_io, 'r') as z:\n                file_list = z.namelist()\n                for file_name in file_list:\n                    extract_and_save_file(zip_bytes_io, file_name, output_path + file_name)\n        \n        # Aplica a fun\u00e7\u00e3o a cada arquivo no RDD\n        rdd.foreach(process_zip_file)"}, {"cell_type": "markdown", "id": "8d083cc8-14a3-4e69-8e24-8f856c3b78ab", "metadata": {}, "source": "# Dezipar dados de estabelecimento"}, {"cell_type": "code", "execution_count": 8, "id": "66d6a149-2281-4366-acd5-16d58e523478", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "from pyspark.sql import SparkSession\n\n# Definindo a sess\u00e3o do Spark\nspark = SparkSession.builder.appName(\"ExtractZipFiles\").getOrCreate()\n\n# Fun\u00e7\u00e3o para processar cada arquivo zip\ndef process_zip_file(zip_file_path):\n    import io\n    import zipfile\n    import gcsfs\n    \n    # Gera o caminho de sa\u00edda com base no nome do arquivo ZIP\n    output_path = 'gs://projeto-dados-receita-federal/Estabelecimentos/arquivo_deszipado/'\n    \n    # Cria uma inst\u00e2ncia do sistema de arquivos do GCS\n    fs = gcsfs.GCSFileSystem()\n    \n    # L\u00ea o arquivo zip como bytes usando gcsfs diretamente\n    with fs.open(zip_file_path, 'rb') as f_zip:\n        zip_bytes_io = io.BytesIO(f_zip.read())\n        \n        with zipfile.ZipFile(zip_bytes_io, 'r') as z:\n            file_list = z.namelist()\n            for file_name in file_list:\n                with z.open(file_name) as specific_file, fs.open(output_path + file_name, 'wb') as f_out:\n                    # L\u00ea e escreve em partes para evitar o uso excessivo de mem\u00f3ria\n                    for data in iter(lambda: specific_file.read(4096), b''):\n                        f_out.write(data)\n                print(f\"File {file_name} extracted and saved to {output_path + file_name}\")\n\n# Vari\u00e1veis para o nome do bucket e o prefixo dos arquivos\nbucket_name = 'projeto-dados-receita-federal'\nprefix = 'Estabelecimentos'\n\n# Lista de caminhos dos arquivos ZIP\nzip_files_paths = [f'gs://projeto-dados-receita-federal/Estabelecimentos/{prefix}{i}.zip' for i in range(10)]\n\n# Distribui o processamento dos arquivos ZIP\nrdd = spark.sparkContext.parallelize(zip_files_paths)\nrdd.foreach(process_zip_file)\n"}, {"cell_type": "code", "execution_count": null, "id": "919e395e-66b9-41f9-8c71-f497bc1755f9", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.8"}, "toc-autonumbering": true}, "nbformat": 4, "nbformat_minor": 5}